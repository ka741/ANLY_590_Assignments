{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESPf6Tz0Tn-w"
      },
      "source": [
        "# 1) Autoencoder\n",
        ">A convolutional autoencoder is a particular flavor of autoencoder where we\n",
        "use convolutional layers instead of Dense layers. We have previously applied\n",
        "autoencoders to images using only Dense layers and the result worked fairly\n",
        "well. However, the local spatial correlations of images imply that we should\n",
        "Be able to do better using convolutional layers instead of Dense layers.\n",
        "Build and fit a convolutional autoencoder for the CIFAR10 dataset.\n",
        "The components of this network will be many of the same pieces we’ve used\n",
        "with convolutional classification networks: Conv2D, MaxPooling, and so on.\n",
        "The encoder part of the network should run the input image through a few\n",
        "convolutional layers of your choice. The decoder part of the network will utilize UpSampling2D to get the representation back to the original image size.\n",
        "An example to guide your thinking can be found toward the bottom of this\n",
        "Post https://blog.keras.io/building-autoencoders-in-keras.html.\n",
        "DO NOT JUST COPY THIS CODE AND TURN IT IN. BE CREATIVE,\n",
        "COME UP WITH YOUR OWN VARIATION.\n",
        "After training your network, visualize some examples of input images and\n",
        "their decoded reconstruction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JqD2p_1RlZr"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as tfk\n",
        "import tensorflow_datasets as tfds\n",
        "import keras\n",
        "from keras import layers\n",
        "tfkl = tfk.layers"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TInVKnMsSoLq"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = np.reshape(x_train, (len(x_train), 32, 32, 3))\n",
        "x_test = np.reshape(x_test, (len(x_test), 32, 32, 3))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMiou1VlRVOC",
        "outputId": "77b587a7-dead-4044-a877-5d17b4700e78"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lm4qXsWRSHRx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68f31a30-6cf9-4789-8313-af65052d27bc"
      },
      "source": [
        "'''I tied this and it performed very poorly\n",
        "\n",
        "input_img = keras.Input(shape=(32, 32, 3))\n",
        "\n",
        "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "x = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
        "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "x = layers.Conv2D(2, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "x = layers.Conv2D(2, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "\n",
        "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "\n",
        "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "\n",
        "decoded = layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "autoencoder = keras.Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer=tfk.optimizers.Adam(),loss=tfk.losses.BinaryCrossentropy())\n",
        "autoencoder.summary()\n",
        "'''"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_79\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_41 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d_358 (Conv2D)          (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_185 (MaxPoolin (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_359 (Conv2D)          (None, 16, 16, 16)        4624      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_186 (MaxPoolin (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_360 (Conv2D)          (None, 8, 8, 8)           1160      \n",
            "_________________________________________________________________\n",
            "conv2d_361 (Conv2D)          (None, 8, 8, 2)           146       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_188 (MaxPoolin (None, 4, 4, 2)           0         \n",
            "_________________________________________________________________\n",
            "conv2d_362 (Conv2D)          (None, 4, 4, 2)           38        \n",
            "_________________________________________________________________\n",
            "up_sampling2d_125 (UpSamplin (None, 8, 8, 2)           0         \n",
            "_________________________________________________________________\n",
            "conv2d_363 (Conv2D)          (None, 8, 8, 8)           152       \n",
            "_________________________________________________________________\n",
            "up_sampling2d_126 (UpSamplin (None, 16, 16, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_364 (Conv2D)          (None, 16, 16, 8)         584       \n",
            "_________________________________________________________________\n",
            "up_sampling2d_127 (UpSamplin (None, 32, 32, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_365 (Conv2D)          (None, 32, 32, 3)         219       \n",
            "=================================================================\n",
            "Total params: 7,819\n",
            "Trainable params: 7,819\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gFZgJTsev6t",
        "outputId": "5682bb57-c1e4-4d03-ce14-3516c4397e85"
      },
      "source": [
        "input_img = keras.Input(shape=(32, 32, 3))\n",
        "\n",
        "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "x = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
        "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "\n",
        "x = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "\n",
        "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "\n",
        "decoded = layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "autoencoder = keras.Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer=tfk.optimizers.Adam(),loss=tfk.losses.BinaryCrossentropy())\n",
        "autoencoder.summary()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_85\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_45 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d_383 (Conv2D)          (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_196 (MaxPoolin (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_384 (Conv2D)          (None, 16, 16, 16)        4624      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_197 (MaxPoolin (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_385 (Conv2D)          (None, 8, 8, 8)           1160      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_198 (MaxPoolin (None, 4, 4, 8)           0         \n",
            "_________________________________________________________________\n",
            "conv2d_386 (Conv2D)          (None, 4, 4, 8)           584       \n",
            "_________________________________________________________________\n",
            "up_sampling2d_135 (UpSamplin (None, 8, 8, 8)           0         \n",
            "_________________________________________________________________\n",
            "conv2d_387 (Conv2D)          (None, 8, 8, 16)          1168      \n",
            "_________________________________________________________________\n",
            "up_sampling2d_136 (UpSamplin (None, 16, 16, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_388 (Conv2D)          (None, 16, 16, 32)        4640      \n",
            "_________________________________________________________________\n",
            "up_sampling2d_137 (UpSamplin (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_389 (Conv2D)          (None, 32, 32, 3)         867       \n",
            "=================================================================\n",
            "Total params: 13,939\n",
            "Trainable params: 13,939\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IgxgDGES3u5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "579107d0-8bbb-49ce-ee00-510908199dd1"
      },
      "source": [
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=20,\n",
        "                batch_size=128,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "391/391 [==============================] - 166s 424ms/step - loss: 0.6070 - val_loss: 0.5913\n",
            "Epoch 2/20\n",
            "391/391 [==============================] - 165s 421ms/step - loss: 0.5880 - val_loss: 0.5864\n",
            "Epoch 3/20\n",
            "391/391 [==============================] - 165s 421ms/step - loss: 0.5845 - val_loss: 0.5851\n",
            "Epoch 4/20\n",
            "391/391 [==============================] - 165s 422ms/step - loss: 0.5826 - val_loss: 0.5847\n",
            "Epoch 5/20\n",
            "391/391 [==============================] - 164s 419ms/step - loss: 0.5815 - val_loss: 0.5815\n",
            "Epoch 6/20\n",
            "391/391 [==============================] - 164s 420ms/step - loss: 0.5806 - val_loss: 0.5807\n",
            "Epoch 7/20\n",
            "391/391 [==============================] - 164s 420ms/step - loss: 0.5798 - val_loss: 0.5807\n",
            "Epoch 8/20\n",
            "391/391 [==============================] - 164s 419ms/step - loss: 0.5792 - val_loss: 0.5795\n",
            "Epoch 9/20\n",
            "391/391 [==============================] - 164s 420ms/step - loss: 0.5786 - val_loss: 0.5805\n",
            "Epoch 10/20\n",
            "391/391 [==============================] - 164s 420ms/step - loss: 0.5781 - val_loss: 0.5805\n",
            "Epoch 11/20\n",
            "391/391 [==============================] - 164s 419ms/step - loss: 0.5777 - val_loss: 0.5787\n",
            "Epoch 12/20\n",
            "391/391 [==============================] - 164s 420ms/step - loss: 0.5773 - val_loss: 0.5780\n",
            "Epoch 13/20\n",
            "391/391 [==============================] - 164s 420ms/step - loss: 0.5770 - val_loss: 0.5774\n",
            "Epoch 14/20\n",
            "391/391 [==============================] - 164s 420ms/step - loss: 0.5767 - val_loss: 0.5773\n",
            "Epoch 15/20\n",
            "391/391 [==============================] - 164s 420ms/step - loss: 0.5764 - val_loss: 0.5774\n",
            "Epoch 16/20\n",
            "218/391 [===============>..............] - ETA: 1:09 - loss: 0.5763"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SODuao-xbuas"
      },
      "source": [
        "decoded_imgs = autoencoder.predict(x_test)\n",
        "\n",
        "n = 5\n",
        "plt.figure(figsize=(15, 5))\n",
        "for i in range(1, n + 1):\n",
        "    ax = plt.subplot(2, n, i)\n",
        "    plt.imshow(x_test[i].reshape(32, 32, 3))\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    ax = plt.subplot(2, n, i + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(32, 32, 3))\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MT7TLvVWT2zk"
      },
      "source": [
        "# 2) Image Classification\n",
        ">We’ll continue to use the CIFAR10 dataset and build a deep convolutional\n",
        "network for classification.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKeYpXJ7T8-V"
      },
      "source": [
        "## 2.1) Deep CNN\n",
        ">Build a deep CNN to classify the images. Provide a brief description of the\n",
        "architectural choices you’ve made: kernel sizes, strides, padding, network\n",
        "depth.Train your network end-to-end. Report on your model’s performance\n",
        "on the training set and test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tzXfqiikJMf"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2eTG-GUT783"
      },
      "source": [
        "y_train = tfk.utils.to_categorical(y_train)\n",
        "y_test = tfk.utils.to_categorical(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-6nLdl2eKhT"
      },
      "source": [
        "img_shape = (32,32,2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XP43CTHxflwY"
      },
      "source": [
        "cnn = tfk.Sequential()\n",
        "# I used a kernel size of 3x3 and took strides of 1\n",
        "cnn.add(tfkl.Conv2D(filters = 32, kernel_size=(3,3), strides=(1,1), \n",
        "                      padding=\"valid\", activation='relu', input_shape=(32, 32, 3)))\n",
        "\n",
        "# I included max pooling in order to weight important features\n",
        "cnn.add(tfkl.MaxPool2D(pool_size=(4,4)))\n",
        "# I also included dropout to prevent overfitting\n",
        "cnn.add(tfkl.Dropout(.25))\n",
        "\n",
        "cnn.add(tfkl.Flatten())\n",
        "cnn.add(tfkl.Dense(10, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74CE4liEg7et"
      },
      "source": [
        "cnn.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEYopi8shD4N"
      },
      "source": [
        "cnn.compile(\n",
        "    optimizer=tfk.optimizers.RMSprop(),\n",
        "    loss=tfk.losses.CategoricalCrossentropy(),\n",
        ")\n",
        "\n",
        "results = cnn.fit(images, labels, batch_size=32, epochs=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pGnKEoChQwk"
      },
      "source": [
        "plt.plot(results.history[\"loss\"])\n",
        "plt.plot(results.history[\"val_loss\"])\n",
        "plt.legend(labels=[\"train\", \"val\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAZ_vgMqhWzo"
      },
      "source": [
        "plt.stem(model.predict(ds_test.take(1))[9, :]) # pull one batch of images and the ninth image in that batch\n",
        "# visulaize the prediction of the softmax for this image\n",
        "plt.xlabel(\"Digit\")\n",
        "plt.xlabel(\"Probability\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAl-CotRUDeE"
      },
      "source": [
        "## 2.2) Transfer Learning\n",
        ">Repeat the same task, but this time utilize a pre-trained network for the majority of your model. You should only train the final Dense layer, all other weights\n",
        "should be fixed. You can use whichever pre-trained backbone you like (ResNet,\n",
        "VGG, etc). Report on your model’s performance on the training set and test\n",
        "set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgehj9tDUG4h"
      },
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "conv_base = VGG16(weights=\"imagenet\",include_top=False,input_shape=(300,300,3))\n",
        "conv_base.trainable = False # make sure the VGG16 is fixed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ocgu4_d3hjEZ"
      },
      "source": [
        "model_transfer = tfk.Sequential()\n",
        "model_transfer.add(conv_base)\n",
        "\n",
        "# add Dense layers\n",
        "model_transfer.add(tfkl.GlobalMaxPool2D())\n",
        "model_transfer.add(tfkl.Dense(150, activation='relu'))\n",
        "model_transfer.add(tfkl.Dropout(.25))\n",
        "model_transfer.add(tfkl.Dense(3, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IrzveMuiARq"
      },
      "source": [
        "model_transfer.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biy8xuywiCYC"
      },
      "source": [
        "model_transfer.compile(\n",
        "    optimizer=tfk.optimizers.RMSprop(),\n",
        "    loss=tfk.losses.CategoricalCrossentropy(),\n",
        ")\n",
        "\n",
        "results = model.fit(images, labels, batch_size=32, epochs=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rf_a6Er4iQyC"
      },
      "source": [
        "plt.plot(results.history[\"loss\"])\n",
        "plt.plot(results.history[\"val_loss\"])\n",
        "plt.legend(labels=[\"train\", \"val\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMHpzYfVUHsV"
      },
      "source": [
        "# 3) Text Classification\n",
        "> While images contain local spatial correlations and structure, many other\n",
        "datasets contain temporal correlations. Examples include time series and discrete sequences such as text. In this problem, we will tackle the task of text classification in the context of natural language. <br>\n",
        "\n",
        "><b> Background.</b> In this problem, we will build models that read text segments (messages) and identify whether they are SPAM or HAM.<br>\n",
        "\n",
        ">Wikipedia describes SPAM as “the use of electronic messaging systems to\n",
        "send unsolicited bulk messages, especially advertising, indiscriminately.” <br>\n",
        "\n",
        ">The term ‘HAM’ was originally coined by SpamBayes sometime around 2001\n",
        "and is currently defined and understood to be “E-mail that is generally desired\n",
        "and isn’t considered SPAM.” <br>\n",
        "\n",
        "><b> Dataset </b>. The dataset consists of ∼ 5500 messages along with binary labels(SPAM or HAM) and is already preprocessed. So basically each sample is\n",
        "like [MESSAGE, LABEL].\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxiE6tb8URh-"
      },
      "source": [
        "## 3.1) RNN\n",
        "> Build and train a Recurrent Neural Network to solve this text classification\n",
        "task. You can use any type of RNN you wish (SimpleRNN, GRU, LSTM)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CK1OONRBnwCF"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUUEZYVbUOQY"
      },
      "source": [
        "spam = pd.read_('/SPAM_detection')\n",
        "spam.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPnFpMdkUTEa"
      },
      "source": [
        "x = spam['Message']\n",
        "y = spam['category_val']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6LPHfKIlVpn"
      },
      "source": [
        "tokenizer = keras.preprocessing.text.Tokenizer(num_words=None,\n",
        "                filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True,\n",
        "    split=' ', char_level=False, oov_token=None)\n",
        "tokenizer.fit_on_texts(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIG1OfAXlEIx"
      },
      "source": [
        "x = tokenizer.texts_to_sequences(x)\n",
        "x = tfk.preprocessing.sequence.pad_sequences(\n",
        "    x, maxlen=None, dtype='int32', padding='pre', truncating='pre',\n",
        "    value=0.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlRzFq2PnhQS"
      },
      "source": [
        "y = pd.get_dummies(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXyxiUa_oKw1"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.25, random_state=4)\n",
        "tot_words = 1+len(tokenizer.word_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NHL_DtAoMbM"
      },
      "source": [
        "rnn = tfk.Sequential()\n",
        "rnn.add(tfkl.Embedding())\n",
        "\n",
        "# add Dense layers\n",
        "rnn.add(tfkl.GlobalMaxPool2D())\n",
        "rnn.add(tfkl.Dense(150, activation='relu'))\n",
        "rnn.add(tfkl.Dropout(.25))\n",
        "rnn.add(tfkl.Dense(3, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNX-doX-UTqz"
      },
      "source": [
        "## 3.2) CNN\n",
        "> Build and train a 1D CNN for this text classification task. We recommend\n",
        "you do a character-level convolution (with character embeddings). You might\n",
        "gain some insight and inspiration from these text classification approaches:<br>\n",
        "1.http://www.aclweb.org/anthology/D14-1181 <br>\n",
        "2.https://arxiv.org/abs/1702.08568 <br>\n",
        "Tips: after splitting every character in each training sample, the maximum\n",
        "length of training samples can be really big. If you choose to only do the\n",
        "padding trick to all the samples, it might raise OOM issues. So instead of\n",
        "padding only, you can also cut each sample at a certain p"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxQl5qroUWad"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMlc6kVEUaxK"
      },
      "source": [
        "## 3.3) Compaire\n",
        "> Be sure to directly compare your two methods with an ROC curve or similar\n",
        "validation method. Don’t forget to create a train-test split.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bk0lJfyoUcwX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}